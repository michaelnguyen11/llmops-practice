{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from typing import List, Tuple\n",
    "from datasets import Dataset\n",
    "from openai import OpenAI\n",
    "from pydantic import Field\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_articles_from_json(file_path: str) -> Dataset:\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            \"id\": [item[\"id\"] for item in data[\"artifact_data\"]],\n",
    "            \"content\": [item[\"content\"] for item in data[\"artifact_data\"]],\n",
    "            \"platform\": [item[\"platform\"] for item in data[\"artifact_data\"]],\n",
    "            \"author_id\": [item[\"author_id\"] for item in data[\"artifact_data\"]],\n",
    "            \"author_full_name\": [item[\"author_full_name\"] for item in data[\"artifact_data\"]],\n",
    "            \"link\": [item[\"link\"] for item in data[\"artifact_data\"]],\n",
    "        }\n",
    "    )\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove non-alphanumeric characters except for apostrophe, periods, commas, exclamation marks and question marks\n",
    "    text = re.sub(r\"[^\\w\\s.,!?']\", \" \", text)\n",
    "    # Replace multiple consecutive whitespace characters with a single space\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_substrings(dataset: Dataset, min_length: int = 1000, max_length: int = 2000) -> List[str]:\n",
    "    extracts = []\n",
    "\n",
    "    # To make sure that the splitting doesn't break sentences, which could modify their meanings\n",
    "    # Use a regex to only split after the end of a sentence.\n",
    "    sentence_pattern = r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s\"\n",
    "    for article in dataset[\"content\"]:\n",
    "        cleaned_article = clean_text(article)\n",
    "        sentences = re.split(sentence_pattern, cleaned_article)\n",
    "\n",
    "        current_chunk = \"\"\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence:\n",
    "                continue\n",
    "\n",
    "            if len(current_chunk) + len(sentence) <= max_length:\n",
    "                current_chunk += sentence + \" \"\n",
    "            else:\n",
    "                if len(current_chunk) >= min_length:\n",
    "                    extracts.append(current_chunk.strip())\n",
    "                current_chunk = sentence + \" \"\n",
    "\n",
    "        if len(current_chunk) >= min_length:\n",
    "            extracts.append(current_chunk.strip())\n",
    "\n",
    "    return extracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreferenceSet:\n",
    "    def __init__(self, triples: List[Tuple[str, str, str]]):\n",
    "        # instructions, generated answers(rejected), and extracted answers(chosen)\n",
    "        self.triples = triples\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, json_str: str) -> \"PreferenceSet\":\n",
    "        data = json.loads(json_str)\n",
    "        triples = [\n",
    "            (\n",
    "                triple[\"instruction\"],\n",
    "                triple[\"generated_answer\"],\n",
    "                triple[\"extracted_answer\"],\n",
    "            )\n",
    "            for triple in data[\"preference_triples\"]\n",
    "        ]\n",
    "        return cls(triples)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_preference_triples(\n",
    "    extract: str, client: OpenAI\n",
    ") -> List[Tuple[str, str, str]]:\n",
    "    prompt = f\"\"\"Based on the following extract, generate five instruction-answer triples. Each triple should consist of:\n",
    "1. An instruction asking about a specific topic in the context.\n",
    "2. A generated answer that attempts to answer the instruction based on the context.\n",
    "3. An extracted answer that is a relevant excerpt directly from the given context.\n",
    "Instructions must be self-contained and general, without explicitly mentioning a context, system, course, or extract.\n",
    "Important:\n",
    "- Ensure that the extracted answer is a verbatim copy from the context, including all punctuation and apostrophes.\n",
    "- Do not add any ellipsis (...) or [...]  to indicate skipped text in the extracted answer.\n",
    "- If the relevant text is not continuous, use two separate sentences from the context instead of skipping text.\n",
    "Provide your response in JSON format with the following structure:\n",
    "{{\n",
    "    \"preference_triples\": [\n",
    "        {{\n",
    "            \"instruction\": \"...\",\n",
    "            \"generated_answer\": \"...\",\n",
    "            \"extracted_answer\": \"...\"\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "    Extract:\n",
    "    {extract}\n",
    "\"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who generates instruction-answer triples based on the given context. Each triple should include an instruction, a generated answer, and an extracted answer from the context. Provide your response in JSON format.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        max_tokens=2000,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    result = PreferenceSet.from_json(completion.choices[0].message.content)\n",
    "    return result.triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short_answers(dataset: Dataset, min_length: int = 100) -> Dataset:\n",
    "    def is_long_enough(example):\n",
    "        return len(example[\"chosen\"]) >= min_length\n",
    "\n",
    "    return dataset.filter(is_long_enough)\n",
    "\n",
    "\n",
    "def filter_answer_format(dataset: Dataset) -> Dataset:\n",
    "    def is_valid_format(example):\n",
    "        chosen = example[\"chosen\"]\n",
    "        return len(chosen) > 0 and chosen[0].isupper() and chosen[-1] in (\".\", \"!\", \"?\")\n",
    "\n",
    "    return dataset.filter(is_valid_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preference_dataset(\n",
    "    dataset: Dataset, client: OpenAI, num_workers: int = 4\n",
    ") -> Dataset:\n",
    "    extracts = extract_substrings(dataset)\n",
    "    preference_triples = []\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(generate_preference_triples, extract, client)\n",
    "            for extract in extracts\n",
    "        ]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "            preference_triples.extend(future.result())\n",
    "\n",
    "    instructions, generated_answers, extracted_answers = zip(*preference_triples)\n",
    "\n",
    "    # return Dataset.from_dict(\n",
    "    #     {\n",
    "    #         \"prompt\": list(instructions),\n",
    "    #         \"rejected\": list(generated_answers),\n",
    "    #         \"chosen\": list(extracted_answers),\n",
    "    #     }\n",
    "    # )\n",
    "\n",
    "    return Dataset.from_dict(\n",
    "        {\n",
    "            \"prompt\": list(instructions),\n",
    "            \"rejected\": list(extracted_answers),\n",
    "            \"chosen\": list(generated_answers),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# 1. Load the raw data\n",
    "raw_dataset = load_articles_from_json(\"../output/cleaned_documents.json\")\n",
    "print(\"Raw dataset:\")\n",
    "print(raw_dataset.to_pandas())\n",
    "\n",
    "# 2. Create preference dataset\n",
    "dataset = create_preference_dataset(raw_dataset, client)\n",
    "print(\"Preference dataset:\")\n",
    "print(dataset.to_pandas())\n",
    "\n",
    "# 3. Filter out samples with short answers\n",
    "dataset = filter_short_answers(dataset)\n",
    "\n",
    "# 4. Filter answers based on format\n",
    "dataset = filter_answer_format(dataset)\n",
    "\n",
    "# 5. Export\n",
    "dataset.push_to_hub(\"michaelnguyen11/llm_twin_dpo\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
